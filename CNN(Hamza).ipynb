{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv8nKd6Q7Pk4ruNvnvT5OG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzaodeh/Group-A-DLI-Assignment/blob/main/CNN(Hamza).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 1: setup, imports, seeds, hyperparams ---\n",
        "\n",
        "# (If Opacus isn't present)\n",
        "# !pip install opacus==1.4.0\n",
        "\n",
        "import os, time, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, roc_auc_score\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.uniform_sampler import UniformWithReplacementSampler\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# --- Federated + DP hyperparams you can tune ---\n",
        "NUM_CLIENTS   = 2\n",
        "ROUNDS        = 35         # fewer, better rounds usually help under DP\n",
        "BATCH         = 256        # DP \"physical\" batch via Poisson sampling\n",
        "NOISE         = 0.5        # DP noise multiplier (0.3â€“0.5 good starting range)\n",
        "CLIP          = 1.0        # DP max grad norm\n",
        "LR            = 1e-3       # AdamW LR\n",
        "WEIGHT_DECAY  = 1e-4\n",
        "LABEL_SMOOTH  = 0.0        # leave 0.0 for accuracy; >0 can improve recall but drop acc\n",
        "\n",
        "print(f\"[Info] hyperparams: rounds={ROUNDS}, batch={BATCH}, noise={NOISE}, clip={CLIP}, lr={LR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGfGqVfxWN9A",
        "outputId": "70a604d3-c51c-4bae-8711-856213f8f882"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "[Info] hyperparams: rounds=35, batch=256, noise=0.5, clip=1.0, lr=0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 2: load & basic clean (keep only numeric + Label, no NAs) ---\n",
        "\n",
        "csv_file = \"/content/wustl-ehms-2020_with_attacks_categories.csv\"\n",
        "assert os.path.exists(csv_file), f\"CSV not found at: {csv_file}\"\n",
        "\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Keep only numeric columns and ensure 'Label' exists and is last\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "if \"Label\" not in numeric_cols and \"Label\" in df.columns:\n",
        "    numeric_cols.append(\"Label\")\n",
        "\n",
        "df = df[numeric_cols].dropna().reset_index(drop=True)\n",
        "\n",
        "# Move Label to last column (explicit)\n",
        "if df.columns[-1] != \"Label\":\n",
        "    cols = [c for c in df.columns if c != \"Label\"] + [\"Label\"]\n",
        "    df = df[cols]\n",
        "\n",
        "print(\"Columns:\", list(df.columns))\n",
        "print(\"Shape after cleaning:\", df.shape)\n",
        "\n",
        "# Detect feature size\n",
        "input_features = df.shape[1] - 1\n",
        "print(f\"[Info] input_features={input_features}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmUiu5YpW_e-",
        "outputId": "a2cc2375-375b-4440-ed14-1d036e499052"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['Dport', 'SrcBytes', 'DstBytes', 'SrcLoad', 'DstLoad', 'SrcGap', 'DstGap', 'SIntPkt', 'DIntPkt', 'SIntPktAct', 'DIntPktAct', 'SrcJitter', 'DstJitter', 'sMaxPktSz', 'dMaxPktSz', 'sMinPktSz', 'dMinPktSz', 'Dur', 'Trans', 'TotPkts', 'TotBytes', 'Load', 'Loss', 'pLoss', 'pSrcLoss', 'pDstLoss', 'Rate', 'Packet_num', 'Temp', 'SpO2', 'Pulse_Rate', 'SYS', 'DIA', 'Heart_rate', 'Resp_Rate', 'ST', 'Label']\n",
            "Shape after cleaning: (16318, 37)\n",
            "[Info] input_features=36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 3: stratified train/val/test split + scale on train only ---\n",
        "\n",
        "class DatasetLoader:\n",
        "    def __init__(self, df, train_frac=0.7, val_frac=0.1, test_frac=0.2, seed=42):\n",
        "        assert abs(train_frac + val_frac + test_frac - 1.0) < 1e-6\n",
        "        self.seed = seed\n",
        "\n",
        "        y_all = df[\"Label\"].astype(int).values\n",
        "        X_all = df.drop(columns=[\"Label\"]).astype(np.float32).values\n",
        "\n",
        "        # Stratified train/test\n",
        "        X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "            X_all, y_all, test_size=test_frac, stratify=y_all, random_state=seed\n",
        "        )\n",
        "        # Stratified train/val\n",
        "        val_size = val_frac / (train_frac + val_frac)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_trainval, y_trainval, test_size=val_size, stratify=y_trainval, random_state=seed\n",
        "        )\n",
        "\n",
        "        # Scale on train only\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train).astype(np.float32)\n",
        "        X_val   = scaler.transform(X_val).astype(np.float32)\n",
        "        X_test  = scaler.transform(X_test).astype(np.float32)\n",
        "\n",
        "        self._X_train, self._y_train = X_train, y_train\n",
        "        self._X_val,   self._y_val   = X_val,   y_val\n",
        "        self._X_test,  self._y_test  = X_test,  y_test\n",
        "\n",
        "    @property\n",
        "    def X_train(self): return self._X_train\n",
        "    @property\n",
        "    def y_train(self): return self._y_train\n",
        "    @property\n",
        "    def X_val(self):   return self._X_val\n",
        "    @property\n",
        "    def y_val(self):   return self._y_val\n",
        "    @property\n",
        "    def X_test(self):  return self._X_test\n",
        "    @property\n",
        "    def y_test(self):  return self._y_test\n",
        "\n",
        "dloader = DatasetLoader(df, train_frac=0.7, val_frac=0.1, test_frac=0.2, seed=SEED)\n",
        "print(\"Train/Val/Test sizes:\", len(dloader.X_train), len(dloader.X_val), len(dloader.X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh8XsYCkP-aL",
        "outputId": "c7de8fb3-93fa-4662-a2f7-068d57cd4f99"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val/Test sizes: 11422 1632 3264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 4: build client DP loaders + val/test loaders ---\n",
        "\n",
        "def split_clients(X, y, num_clients):\n",
        "    n = len(X)\n",
        "    per = n // num_clients\n",
        "    splits = []\n",
        "    for i in range(num_clients):\n",
        "        s = i*per\n",
        "        e = (i+1)*per if i < num_clients-1 else n\n",
        "        splits.append((X[s:e], y[s:e]))\n",
        "    return splits\n",
        "\n",
        "client_splits = split_clients(dloader.X_train, dloader.y_train, NUM_CLIENTS)\n",
        "\n",
        "# Class weights (boost minority class)\n",
        "pos = (dloader.y_train == 1).sum()\n",
        "neg = (dloader.y_train == 0).sum()\n",
        "pos_weight = max(1.0, min(5.0, neg / max(1, pos)))  # cap to [1,5] to avoid exploding gradients\n",
        "CLASS_WEIGHTS_TENSOR = torch.tensor([1.0, pos_weight], dtype=torch.float32, device=device)\n",
        "print(f\"[Info] class weights: normal=1.0, attack={pos_weight:.2f}\")\n",
        "\n",
        "# Poisson-sampled DP loader for each client (required by Opacus)\n",
        "def make_dp_client_loader(Xc, yc, batch_size=BATCH):\n",
        "    Xc_t = torch.tensor(Xc, dtype=torch.float32)\n",
        "    yc_t = torch.tensor(yc, dtype=torch.long)\n",
        "    ds = TensorDataset(Xc_t, yc_t)\n",
        "    N = len(ds)\n",
        "    sample_rate = batch_size / float(N)\n",
        "    sampler = UniformWithReplacementSampler(num_samples=N, sample_rate=sample_rate)\n",
        "    return DataLoader(ds, batch_sampler=sampler, num_workers=1, pin_memory=False), N\n",
        "\n",
        "client_loaders = {}\n",
        "client_sizes   = {}\n",
        "for i, (Xc, yc) in enumerate(client_splits):\n",
        "    ld, N = make_dp_client_loader(Xc, yc, batch_size=BATCH)\n",
        "    client_loaders[f\"client_{i}\"] = ld\n",
        "    client_sizes[f\"client_{i}\"]   = N\n",
        "\n",
        "# Val & Test standard loaders\n",
        "val_loader = DataLoader(\n",
        "    TensorDataset(torch.tensor(dloader.X_val, dtype=torch.float32),\n",
        "                  torch.tensor(dloader.y_val, dtype=torch.long)),\n",
        "    batch_size=BATCH, shuffle=False, num_workers=1, pin_memory=False\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    TensorDataset(torch.tensor(dloader.X_test, dtype=torch.float32),\n",
        "                  torch.tensor(dloader.y_test, dtype=torch.long)),\n",
        "    batch_size=BATCH, shuffle=False, num_workers=1, pin_memory=False\n",
        ")\n",
        "\n",
        "print(\"[Info] clients:\", {k: len(v) for k, v in client_loaders.items()},\n",
        "      \"| val batches:\", len(val_loader), \"| test batches:\", len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkvN93PbQB97",
        "outputId": "d05db7b5-86e3-4e73-80ee-1a9a0de17b63"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] class weights: normal=1.0, attack=5.00\n",
            "[Info] clients: {'client_0': 22, 'client_1': 22} | val batches: 7 | test batches: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 5: DP-safe CNN (1D) with GroupNorm (no BatchNorm!) ---\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_features: int, num_classes: int = 2):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1, bias=True)\n",
        "        self.gn1   = nn.GroupNorm(16, 64)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1, bias=True)\n",
        "        self.gn2   = nn.GroupNorm(16, 128)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "\n",
        "        L = input_features // 4  # after two pool(2) layers\n",
        "        self.fc1 = nn.Linear(128 * L, 192)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(192, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)                # [B,F]â†’[B,1,F]\n",
        "        x = self.pool1(F.relu(self.gn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.gn2(self.conv2(x))))\n",
        "        x = x.flatten(1)\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)                # logits\n"
      ],
      "metadata": {
        "id": "McWVy6g_QIWO"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 6: Server & Client with Opacus DP ---\n",
        "\n",
        "NOISE = NOISE        # from Cell 1 (just keeping visibility)\n",
        "CLIP  = CLIP\n",
        "LR    = LR\n",
        "WEIGHT_DECAY = WEIGHT_DECAY\n",
        "LABEL_SMOOTH = LABEL_SMOOTH\n",
        "\n",
        "class Server:\n",
        "    def __init__(self, model):\n",
        "        self._model = model\n",
        "        self._client_params = []\n",
        "        self._client_sizes  = []\n",
        "    @property\n",
        "    def parameters(self): return self._model.parameters()\n",
        "    @property\n",
        "    def model(self): return self._model\n",
        "    def add_client_parameters(self, parameters, num_samples):\n",
        "        self._client_params.append([p.detach().clone().to(device) for p in parameters])\n",
        "        self._client_sizes.append(num_samples)\n",
        "    def aggregate_parameters(self):\n",
        "        total = float(sum(self._client_sizes))\n",
        "        scaled = []\n",
        "        for plist, n in zip(self._client_params, self._client_sizes):\n",
        "            w = n / total\n",
        "            scaled.append([w * p for p in plist])\n",
        "        agg = [torch.zeros_like(t) for t in scaled[0]]\n",
        "        for plist in scaled:\n",
        "            for j, t in enumerate(plist):\n",
        "                agg[j] += t\n",
        "        with torch.no_grad():\n",
        "            for mp, newp in zip(self._model.parameters(), agg):\n",
        "                mp.data = newp.data.clone()\n",
        "        self._client_params.clear()\n",
        "        self._client_sizes.clear()\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, train_loader, input_features: int):\n",
        "        self._model = CNN(input_features=input_features, num_classes=2).to(device)\n",
        "        self._opt   = optim.AdamW(self._model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "        self._loss  = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS_TENSOR, label_smoothing=LABEL_SMOOTH)\n",
        "        self.train_loader = train_loader\n",
        "        self.privacy_engine = PrivacyEngine(secure_mode=False)\n",
        "        self._model, self._opt, self.train_loader = self.privacy_engine.make_private(\n",
        "            module=self._model,\n",
        "            optimizer=self._opt,\n",
        "            data_loader=self.train_loader,\n",
        "            noise_multiplier=NOISE,\n",
        "            max_grad_norm=CLIP,\n",
        "        )\n",
        "    @property\n",
        "    def parameters(self): return self._model.parameters()\n",
        "    def update_from_server(self, server_params):\n",
        "        with torch.no_grad():\n",
        "            for my_p, srv_p in zip(self._model.parameters(), server_params):\n",
        "                my_p.data = srv_p.detach().clone()\n",
        "    def train_one_epoch(self, epoch: int, name: str):\n",
        "        self._model.train()\n",
        "        losses = []\n",
        "        for xb, yb in self.train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = self._model(xb)\n",
        "            loss = self._loss(logits, yb)\n",
        "            self._opt.zero_grad()\n",
        "            loss.backward()\n",
        "            self._opt.step()\n",
        "            losses.append(loss.item())\n",
        "        eps = self.privacy_engine.get_epsilon(1e-4)\n",
        "        print(f\"Client: {name:>8}  Epoch: {epoch:02d}  Loss: {np.mean(losses):.6f}  (Îµ={eps:.2f})\")\n"
      ],
      "metadata": {
        "id": "JrCK02TgQKyX"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 7: training loop with best-val snapshot + threshold tuning on validation ---\n",
        "\n",
        "def infer_probs(model, loader):\n",
        "    model.eval()\n",
        "    all_logits, all_y = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb)\n",
        "            all_logits.append(logits.cpu())\n",
        "            all_y.append(yb.cpu())\n",
        "    logits = torch.cat(all_logits, 0)\n",
        "    y_true = torch.cat(all_y, 0).numpy()\n",
        "    probs  = F.softmax(logits, dim=1).numpy()\n",
        "    return probs, y_true\n",
        "\n",
        "# Build clients & server\n",
        "clients = {name: Client(ld, input_features) for name, ld in client_loaders.items()}\n",
        "server  = Server(CNN(input_features=input_features, num_classes=2).to(device))\n",
        "\n",
        "t0 = time.time()\n",
        "best_val_acc, best_round, best_snapshot = -1, -1, None\n",
        "\n",
        "for epoch in range(ROUNDS):\n",
        "    srv_params_snapshot = [p.detach().clone() for p in server.parameters]\n",
        "    for name, cl in clients.items():\n",
        "        cl.update_from_server(srv_params_snapshot)\n",
        "        cl.train_one_epoch(epoch, name)\n",
        "        server.add_client_parameters(cl.parameters, num_samples=client_sizes[name])\n",
        "    server.aggregate_parameters()\n",
        "\n",
        "    # quick val acc @ 0.5 threshold to track training\n",
        "    val_probs, val_y = infer_probs(server.model, val_loader)\n",
        "    val_pred_05 = (val_probs[:,1] >= 0.5).astype(int)\n",
        "    val_acc = (val_pred_05 == val_y).mean()\n",
        "    print(f\"[Val @ epoch {epoch}] accuracy={val_acc*100:.2f}%\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_round = epoch\n",
        "        best_snapshot = [p.detach().clone() for p in server.model.parameters()]\n",
        "\n",
        "train_time = time.time() - t0\n",
        "print(f\"[Info] Best val accuracy {best_val_acc*100:.2f}% at round {best_round}\")\n",
        "\n",
        "# Restore best snapshot\n",
        "with torch.no_grad():\n",
        "    for mp, sp in zip(server.model.parameters(), best_snapshot):\n",
        "        mp.data = sp.clone()\n",
        "\n",
        "# Tune decision threshold on validation to maximize accuracy\n",
        "ths = np.linspace(0.01, 0.99, 99)\n",
        "accs = []\n",
        "val_probs, val_y = infer_probs(server.model, val_loader)\n",
        "for t in ths:\n",
        "    accs.append(((val_probs[:,1] >= t).astype(int) == val_y).mean())\n",
        "best_t = float(ths[int(np.argmax(accs))])\n",
        "print(f\"[Info] Best threshold (val, accuracy) = {best_t:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNEdvbVGQM1y",
        "outputId": "f14e7194-b74d-4fc7-d938-17294c280238"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2006213217.py:65: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client: client_0  Epoch: 00  Loss: 2.465805  (Îµ=8.05)\n",
            "Client: client_1  Epoch: 00  Loss: 2.684537  (Îµ=8.05)\n",
            "[Val @ epoch 0] accuracy=87.44%\n",
            "Client: client_0  Epoch: 01  Loss: 1.721759  (Îµ=10.20)\n",
            "Client: client_1  Epoch: 01  Loss: 1.762560  (Îµ=10.20)\n",
            "[Val @ epoch 1] accuracy=87.44%\n",
            "Client: client_0  Epoch: 02  Loss: 1.697062  (Îµ=11.92)\n",
            "Client: client_1  Epoch: 02  Loss: 1.725030  (Îµ=11.92)\n",
            "[Val @ epoch 2] accuracy=87.44%\n",
            "Client: client_0  Epoch: 03  Loss: 1.699450  (Îµ=13.41)\n",
            "Client: client_1  Epoch: 03  Loss: 1.675658  (Îµ=13.41)\n",
            "[Val @ epoch 3] accuracy=87.44%\n",
            "Client: client_0  Epoch: 04  Loss: 1.695631  (Îµ=14.77)\n",
            "Client: client_1  Epoch: 04  Loss: 1.711497  (Îµ=14.77)\n",
            "[Val @ epoch 4] accuracy=87.56%\n",
            "Client: client_0  Epoch: 05  Loss: 1.566354  (Îµ=16.03)\n",
            "Client: client_1  Epoch: 05  Loss: 1.638306  (Îµ=16.03)\n",
            "[Val @ epoch 5] accuracy=87.50%\n",
            "Client: client_0  Epoch: 06  Loss: 1.578429  (Îµ=17.21)\n",
            "Client: client_1  Epoch: 06  Loss: 1.606298  (Îµ=17.21)\n",
            "[Val @ epoch 6] accuracy=87.93%\n",
            "Client: client_0  Epoch: 07  Loss: 1.441731  (Îµ=18.34)\n",
            "Client: client_1  Epoch: 07  Loss: 1.608264  (Îµ=18.34)\n",
            "[Val @ epoch 7] accuracy=89.28%\n",
            "Client: client_0  Epoch: 08  Loss: 1.437128  (Îµ=19.42)\n",
            "Client: client_1  Epoch: 08  Loss: 1.479966  (Îµ=19.42)\n",
            "[Val @ epoch 8] accuracy=91.12%\n",
            "Client: client_0  Epoch: 09  Loss: 1.427964  (Îµ=20.47)\n",
            "Client: client_1  Epoch: 09  Loss: 1.415341  (Îµ=20.47)\n",
            "[Val @ epoch 9] accuracy=92.83%\n",
            "Client: client_0  Epoch: 10  Loss: 1.354292  (Îµ=21.48)\n",
            "Client: client_1  Epoch: 10  Loss: 1.493110  (Îµ=21.48)\n",
            "[Val @ epoch 10] accuracy=92.95%\n",
            "Client: client_0  Epoch: 11  Loss: 1.362892  (Îµ=22.46)\n",
            "Client: client_1  Epoch: 11  Loss: 1.493272  (Îµ=22.46)\n",
            "[Val @ epoch 11] accuracy=92.95%\n",
            "Client: client_0  Epoch: 12  Loss: 1.343813  (Îµ=23.41)\n",
            "Client: client_1  Epoch: 12  Loss: 1.433471  (Îµ=23.41)\n",
            "[Val @ epoch 12] accuracy=92.95%\n",
            "Client: client_0  Epoch: 13  Loss: 1.356470  (Îµ=24.34)\n",
            "Client: client_1  Epoch: 13  Loss: 1.422742  (Îµ=24.34)\n",
            "[Val @ epoch 13] accuracy=92.95%\n",
            "Client: client_0  Epoch: 14  Loss: 1.355509  (Îµ=25.26)\n",
            "Client: client_1  Epoch: 14  Loss: 1.421053  (Îµ=25.26)\n",
            "[Val @ epoch 14] accuracy=92.95%\n",
            "Client: client_0  Epoch: 15  Loss: 1.270946  (Îµ=26.15)\n",
            "Client: client_1  Epoch: 15  Loss: 1.463059  (Îµ=26.15)\n",
            "[Val @ epoch 15] accuracy=92.95%\n",
            "Client: client_0  Epoch: 16  Loss: 1.450790  (Îµ=27.03)\n",
            "Client: client_1  Epoch: 16  Loss: 1.448505  (Îµ=27.03)\n",
            "[Val @ epoch 16] accuracy=92.95%\n",
            "Client: client_0  Epoch: 17  Loss: 1.369058  (Îµ=27.89)\n",
            "Client: client_1  Epoch: 17  Loss: 1.476890  (Îµ=27.89)\n",
            "[Val @ epoch 17] accuracy=92.95%\n",
            "Client: client_0  Epoch: 18  Loss: 1.389699  (Îµ=28.74)\n",
            "Client: client_1  Epoch: 18  Loss: 1.404287  (Îµ=28.74)\n",
            "[Val @ epoch 18] accuracy=92.95%\n",
            "Client: client_0  Epoch: 19  Loss: 1.309944  (Îµ=29.58)\n",
            "Client: client_1  Epoch: 19  Loss: 1.417777  (Îµ=29.58)\n",
            "[Val @ epoch 19] accuracy=92.95%\n",
            "Client: client_0  Epoch: 20  Loss: 1.369726  (Îµ=30.40)\n",
            "Client: client_1  Epoch: 20  Loss: 1.425478  (Îµ=30.40)\n",
            "[Val @ epoch 20] accuracy=92.95%\n",
            "Client: client_0  Epoch: 21  Loss: 1.392139  (Îµ=31.22)\n",
            "Client: client_1  Epoch: 21  Loss: 1.463393  (Îµ=31.22)\n",
            "[Val @ epoch 21] accuracy=92.95%\n",
            "Client: client_0  Epoch: 22  Loss: 1.326215  (Îµ=32.02)\n",
            "Client: client_1  Epoch: 22  Loss: 1.420163  (Îµ=32.02)\n",
            "[Val @ epoch 22] accuracy=92.95%\n",
            "Client: client_0  Epoch: 23  Loss: 1.360734  (Îµ=32.82)\n",
            "Client: client_1  Epoch: 23  Loss: 1.482429  (Îµ=32.82)\n",
            "[Val @ epoch 23] accuracy=92.95%\n",
            "Client: client_0  Epoch: 24  Loss: 1.390290  (Îµ=33.61)\n",
            "Client: client_1  Epoch: 24  Loss: 1.441977  (Îµ=33.61)\n",
            "[Val @ epoch 24] accuracy=92.95%\n",
            "Client: client_0  Epoch: 25  Loss: 1.320646  (Îµ=34.38)\n",
            "Client: client_1  Epoch: 25  Loss: 1.414895  (Îµ=34.38)\n",
            "[Val @ epoch 25] accuracy=92.95%\n",
            "Client: client_0  Epoch: 26  Loss: 1.303285  (Îµ=35.15)\n",
            "Client: client_1  Epoch: 26  Loss: 1.390416  (Îµ=35.15)\n",
            "[Val @ epoch 26] accuracy=92.95%\n",
            "Client: client_0  Epoch: 27  Loss: 1.295590  (Îµ=35.92)\n",
            "Client: client_1  Epoch: 27  Loss: 1.412087  (Îµ=35.92)\n",
            "[Val @ epoch 27] accuracy=92.95%\n",
            "Client: client_0  Epoch: 28  Loss: 1.295818  (Îµ=36.67)\n",
            "Client: client_1  Epoch: 28  Loss: 1.311313  (Îµ=36.67)\n",
            "[Val @ epoch 28] accuracy=92.95%\n",
            "Client: client_0  Epoch: 29  Loss: 1.310225  (Îµ=37.42)\n",
            "Client: client_1  Epoch: 29  Loss: 1.438788  (Îµ=37.42)\n",
            "[Val @ epoch 29] accuracy=92.95%\n",
            "Client: client_0  Epoch: 30  Loss: 1.266729  (Îµ=38.16)\n",
            "Client: client_1  Epoch: 30  Loss: 1.500034  (Îµ=38.16)\n",
            "[Val @ epoch 30] accuracy=92.95%\n",
            "Client: client_0  Epoch: 31  Loss: 1.265165  (Îµ=38.90)\n",
            "Client: client_1  Epoch: 31  Loss: 1.522916  (Îµ=38.90)\n",
            "[Val @ epoch 31] accuracy=92.95%\n",
            "Client: client_0  Epoch: 32  Loss: 1.304263  (Îµ=39.63)\n",
            "Client: client_1  Epoch: 32  Loss: 1.435279  (Îµ=39.63)\n",
            "[Val @ epoch 32] accuracy=92.95%\n",
            "Client: client_0  Epoch: 33  Loss: 1.273506  (Îµ=40.36)\n",
            "Client: client_1  Epoch: 33  Loss: 1.412356  (Îµ=40.36)\n",
            "[Val @ epoch 33] accuracy=92.95%\n",
            "Client: client_0  Epoch: 34  Loss: 1.346932  (Îµ=41.08)\n",
            "Client: client_1  Epoch: 34  Loss: 1.466858  (Îµ=41.08)\n",
            "[Val @ epoch 34] accuracy=92.95%\n",
            "[Info] Best val accuracy 92.95% at round 10\n",
            "[Info] Best threshold (val, accuracy) = 0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 8: final evaluation on test with tuned threshold + table ---\n",
        "\n",
        "def evaluate_with_threshold(model, loader, thr):\n",
        "    probs, y = infer_probs(model, loader)\n",
        "    preds = (probs[:,1] >= thr).astype(int)\n",
        "    acc = accuracy_score(y, preds)\n",
        "    prec = precision_score(y, preds)\n",
        "    rec  = recall_score(y, preds)\n",
        "    f1   = f1_score(y, preds)\n",
        "    auc  = roc_auc_score(y, probs[:,1])\n",
        "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(y, preds))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y, preds))\n",
        "    return acc, prec, rec, f1, auc, preds, probs, y\n",
        "\n",
        "t1 = time.time()\n",
        "acc, prec, rec, f1, auc, preds, probs, y_true = evaluate_with_threshold(server.model, test_loader, best_t)\n",
        "test_time = time.time() - t1\n",
        "\n",
        "epsilon = list(clients.values())[0].privacy_engine.get_epsilon(1e-4)\n",
        "\n",
        "results = pd.DataFrame([{\n",
        "    \"Methods\": \"Federated + CNN (DP)\",\n",
        "    \"Algorithm\": \"CNN\",\n",
        "    \"Accuracy (%)\": round(acc * 100, 2),\n",
        "    \"Precision (%)\": round(prec * 100, 2),\n",
        "    \"Recall (%)\": round(rec * 100, 2),\n",
        "    \"F1-Score (%)\": round(f1 * 100, 2),\n",
        "    \"Train Time (s)\": round(train_time, 2),\n",
        "    \"Test Time (s)\": round(test_time, 2),\n",
        "    \"Privacy Budget (Îµ)\": round(epsilon, 2),\n",
        "    \"Noise\": NOISE,\n",
        "    \"Clip\": CLIP,\n",
        "    \"Rounds\": ROUNDS,\n",
        "    \"Batch\": BATCH,\n",
        "    \"LR\": LR,\n",
        "    \"Threshold\": round(best_t, 2)\n",
        "}])\n",
        "print(\"\\n=== Results Table ===\")\n",
        "print(results.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5_-EZ9-QOkK",
        "outputId": "17cebcb1-cb6e-41a2-f9dd-5fba66e9f799"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion matrix:\n",
            " [[2836   19]\n",
            " [ 197  212]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96      2855\n",
            "           1       0.92      0.52      0.66       409\n",
            "\n",
            "    accuracy                           0.93      3264\n",
            "   macro avg       0.93      0.76      0.81      3264\n",
            "weighted avg       0.93      0.93      0.93      3264\n",
            "\n",
            "\n",
            "=== Results Table ===\n",
            "             Methods Algorithm  Accuracy (%)  Precision (%)  Recall (%)  F1-Score (%)  Train Time (s)  Test Time (s)  Privacy Budget (Îµ)  Noise  Clip  Rounds  Batch    LR  Threshold\n",
            "Federated + CNN (DP)       CNN         93.38          91.77       51.83         66.25          870.81           0.52               41.08    0.5   1.0      35    256 0.001       0.22\n"
          ]
        }
      ]
    }
  ]
}