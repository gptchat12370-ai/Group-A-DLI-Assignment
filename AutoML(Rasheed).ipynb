{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gptchat12370-ai/Group-A-DLI-Assignment/blob/main/AutoML(Rasheed).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import** **libraries**"
      ],
      "metadata": {
        "id": "9-P6QYdQmw5I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZmN7NpIZHSp"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset 1: CICIDS2017**\n",
        "The CICIDS2017 dataset is publicly available at: https://www.unb.ca/cic/datasets/ids-2017.html\n",
        "\n",
        "Due to the large size of this dataset and the file size limit of GitHub, the sampled subset of CICIDS2017 is used. The subsets are in the \"Data\" folder. PS: The results might be different from the paper due to the size difference of the dataset.\n",
        "\n",
        "The Canadian Institute for Cybersecurity Intrusion Detection System 2017 (CICIDS2017) dataset has the most updated network threats. The CICIDS2017 dataset is close to real-world network data since it has a large amount of network traffic data, a variety of network features, various types of attacks, and highly imbalanced classes.\n",
        "\n",
        "# **Load data**"
      ],
      "metadata": {
        "id": "MbyV4RIvm2Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import time"
      ],
      "metadata": {
        "id": "v96W8f4NbBA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset\n",
        "df = pd.read_csv('Data/CICIDS2017_sample_0.02.csv')"
      ],
      "metadata": {
        "id": "Ekz2eGkpbC87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the class distribution of the last column\n",
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "pMv_iiu-bMM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data pre-processing**"
      ],
      "metadata": {
        "id": "qotQy8DonH2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the dataset\n",
        "labelencoder = LabelEncoder()\n",
        "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])"
      ],
      "metadata": {
        "id": "4pyLQo2JrMhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# address empty values\n",
        "if df.isnull().values.any() or np.isinf(df).values.any(): # if there is any empty or infinite values\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.fillna(0, inplace = True)"
      ],
      "metadata": {
        "id": "kcnmvhNgip9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing\n",
        "X = df.drop(['Label'],axis=1).values\n",
        "y = df.iloc[:, -1].values.reshape(-1,1)\n",
        "y=np.ravel(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 0,stratify = y)"
      ],
      "metadata": {
        "id": "9fQRZDYliu2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **model training**\n",
        "**Decision Tree (DT)**"
      ],
      "metadata": {
        "id": "A75hQGGWnNlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Decision tree training and prediction with 3-fold cross-validation\n",
        "dt = DecisionTreeClassifier(random_state=0)\n",
        "dt_scores = cross_val_score(dt, X_train, y_train, cv=3)\n",
        "\n",
        "# calculate the training time\n",
        "start = time.time()\n",
        "dt.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print('Training time: ', end - start)\n",
        "\n",
        "# calculate the prediction time per sample in milliseconds\n",
        "start = time.time()\n",
        "y_predict = dt.predict(X_test)\n",
        "end = time.time()\n",
        "print('Prediction time per sample: ', (end - start) / len(X_test)*1000)\n",
        "\n",
        "y_true = y_test\n",
        "\n",
        "# Print out the cross-validation scores and mean of them\n",
        "print('Cross-Validation scores: ', dt_scores)\n",
        "print('Mean of Cross-Validation scores: ', np.mean(dt_scores))\n",
        "\n",
        "# Evaluation metrics\n",
        "dt_score = dt.score(X_test, y_test)\n",
        "precision, recall, fscore, none = precision_recall_fscore_support(y_true, y_predict, average='weighted')\n",
        "\n",
        "# Print results\n",
        "print('Accuracy of DT: ' + str(dt_score))\n",
        "print('Precision of DT: ' + str(precision))\n",
        "print('Recall of DT: ' + str(recall))\n",
        "print('F1-score of DT: ' + str(fscore))\n",
        "print(classification_report(y_true, y_predict))\n",
        "\n",
        "# Confusion matrix visualization\n",
        "cm = confusion_matrix(y_true, y_predict)\n",
        "f, ax = plt.subplots(figsize=(5, 5))\n",
        "sns.heatmap(cm, annot=True, linewidth=0.5, linecolor=\"red\", fmt=\".0f\", ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gAc3HH43ivoi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}